## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp-zookeeper:
  enabled: true
  servers: 1
  image: confluentinc/cp-zookeeper
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx1024M"
  persistence:
    enabled: true
    ## The size of the PersistentVolume to allocate to each Zookeeper Pod in the StatefulSet. For
    ## production servers this number should likely be much larger.
    ##
    ## Size for Data dir, where ZooKeeper will store the in-memory database snapshots.
    dataDirSize: 10Gi
    # dataDirStorageClass: ""

    ## Size for data log dir, which is a dedicated log device to be used, and helps avoid competition between logging and snaphots.
    dataLogDirSize: 11Gi
    # dataLogDirStorageClass: ""
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------
cp-kafka:
  enabled: true
  brokers: 1
  image: prohankumar/cp-kafka
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx1024M"
  persistence:
    enabled: true
    # storageClass: ""
    size: 5Gi
    disksPerBroker: 1
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi
  env:
    KAFKA_MESSAGE_MAX_BYTES: 100485760
    KAFKA_MAX_PARTITION_FETCH_BYTES: 100485760
    KAFKA_METRIC_REPORTERS: "com.linkedin.kafka.cruisecontrol.metricsreporter.CruiseControlMetricsReporter"
  configurationOverrides:
    "offsets.topic.replication.factor": "1"
    "default.replication.factor": 1
    "min.insync.replicas": 1

## ------------------------------------------------------
## Schema Registry
## ------------------------------------------------------
cp-schema-registry:
  enabled: true
  image: confluentinc/cp-schema-registry
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi


## ------------------------------------------------------
## Kafka Connect
## ------------------------------------------------------
cp-kafka-connect:
  enabled: true
  image: prohankumar/kafka-connect
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi
  configurationOverrides:
    "plugin.path": "/usr/share/java,/usr/share/confluent-hub-components"
    "key.converter": "io.confluent.connect.avro.AvroConverter"
    "value.converter": "io.confluent.connect.avro.AvroConverter"
    "key.converter.schemas.enable": "false"
    "value.converter.schemas.enable": "false"
    "internal.key.converter": "org.apache.kafka.connect.json.JsonConverter"
    "internal.value.converter": "org.apache.kafka.connect.json.JsonConverter"
    "config.storage.replication.factor": "1"
    "offset.storage.replication.factor": "1"
    "status.storage.replication.factor": "1"


consumeroffsetmonitoring:
  enabled: true
  image:
    repository: prohankumar/consumeroffsetsmonitoring
    tag: latest
  kafka:
    consumerOffsetsOutputTopic: consumerOffsetsTest3
    offsetConsumerClientID: Kafka_ConsumerOffsets_Monitor
    offsetConsumerGroupID: consumer-offset
    numberOfRecordsToCommit: 5


eventview:
  enabled: true
  image:
    repository: prohankumar/eventview
    tag: 0.11
  redis:
    port: 6379
    password: redis_pass
  kafka:
    metadataMaxAgeMs: 300000
    consumerGroupID: eventview
  druid:
    taskDuration: PT10M
    completionTimeout: PT20M
  service:
    enabled: true
    httpPort: 80
    nodePort: 32074
    type: NodePort

kafkaadmin:
  enabled: true
  image:
    repository: prohankumar/kafkaadmin
    tag: 0.04
  kafka:
    kafkaConsumerGroupIDAdmin: kafkaAdmin
  druid:
    consumerInfoDataSource: consumerOffsetsTest3
    consumerInfoGranularity: hour
  service:
    enabled: true
    httpPort: 80
    nodePort: 32073
    type: NodePort

metadata:
  enabled: true
  image:
    repository: prohankumar/metadata
    tag: 0.01
  schemaSubjectNamePrefix: metadata
  service:
    enabled: true
    httpPort: 80
    nodePort: 32072
    type: NodePort




joblauncher:
  replicaCount: 1
  image:
    repository: prohankumar/joblauncher
    tag: 0.13
    pullPolicy: IfNotPresent
  kafka:
    consumergroupid: joblauncher
    jobqueuetopic: jobqueue
  profileimagewithtag: prohankumar/profilekafkastreams:0.13
  flowimagewithtag: prohankumar/flowkafkastreams:0.03


joblauncherspark:
  replicaCount: 1
  image:
    repository: prohankumar/joblauncherspark
    tag: 0.02
    pullPolicy: IfNotPresent
  kafka:
    consumergroupid: joblauncherspark
    sparkflowjobqueuetopic: joblauncherspark
  sparkflowimagewithtag: ilanosortap/izac:latest
  SPARK_FLOW_MAIN_APPLICATION_FILE: "local:///opt/spark/examples/jars/izac-distribution-assembly-1.4-Alpha2.jar"



jobserver:
  replicaCount: 1
  image:
    repository: prohankumar/jobserver
    tag: 0.35
    pullPolicy: IfNotPresent
  kafka:
    jobqueuetopic: jobqueue
    SPARK_FLOW_JOB_QUEUE_TOPIC: joblauncherspark
  springContextPath: "/jobserver"


queryconsumeroffsets:
  replicaCount: 1
  image:
    repository: prohankumar/queryconsumeroffsets
    tag: 0.06
    pullPolicy: IfNotPresent
  kafka:
    OFFSET_CONSUMER_GROUP_ID: consumer-offset3
    CONSUMER_OFFSETS_OUTPUT_TOPIC: consumerOffsetsTest3
    AUTO_OFFSET_RESET_CONFIG: earliest
  springContextPath: "/queryconsumeroffsets"