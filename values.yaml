## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp-zookeeper:
  enabled: true
  servers: 3
  image: confluentinc/cp-zookeeper
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx1024M"
  persistence:
    enabled: true
    ## The size of the PersistentVolume to allocate to each Zookeeper Pod in the StatefulSet. For
    ## production servers this number should likely be much larger.
    ##
    ## Size for Data dir, where ZooKeeper will store the in-memory database snapshots.
    dataDirSize: 10Gi
    # dataDirStorageClass: ""

    ## Size for data log dir, which is a dedicated log device to be used, and helps avoid competition between logging and snaphots.
    dataLogDirSize: 11Gi
    # dataLogDirStorageClass: ""
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------
cp-kafka:
  enabled: true
  brokers: 3
  image: confluentinc/cp-kafka
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx1024M"
  persistence:
    enabled: true
    # storageClass: ""
    size: 5Gi
    disksPerBroker: 1
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

## ------------------------------------------------------
## Schema Registry
## ------------------------------------------------------
cp-schema-registry:
  enabled: true
  image: confluentinc/cp-schema-registry
  imageTag: 5.3.1
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi


## ------------------------------------------------------
## Kafka Connect
## ------------------------------------------------------
cp-kafka-connect:
  enabled: true
  image: prohankumar/kafka-connect
  imageTag: latest
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi


consumeroffsetmonitoring:
  enabled: true
  image:
    repository: prohankumar/consumeroffsetsmonitoring
    tag: latest
  kafka:
    consumerOffsetsOutputTopic: consumerOffsetsTest3
    offsetConsumerClientID: Kafka_ConsumerOffsets_Monitor
    offsetConsumerGroupID: consumer-offset
    numberOfRecordsToCommit: 5

druid:
  image:
    repository: apache/incubator-druid
    tag: 0.16.1-incubating
  env:
    druid.coordinator.asOverlord.enabled: true
    DRUID_USE_CONTAINER_IP: true
    # druid_zk_service_host: izac-cp-zookeeper-headless:2181
    # # druid_metadata_storage_host: ""
    # druid_metadata_storage_type: postgresql
    # druid_metadata_storage_connector_connectURI: jdbc:postgresql://izac-postgresql-headless:5432/druid
    # druid_metadata_storage_connector_user: druid
    # druid_metadata_storage_connector_password: FoolishPassword


    # DRUID_XMX: 1g
    # DRUID_XMS: 1g
    # DRUID_MAXNEWSIZE: 250m
    # DRUID_NEWSIZE: 250m
    # DRUID_MAXDIRECTMEMORYSIZE: 6172m

    # druid_emitter_logging_logLevel: debug

    # druid_coordinator_balancer_strategy: cachingCost

    # druid_indexer_fork_property_druid_processing_buffer_sizeBytes: 268435456

  
  broker:
    name: broker
    replicaCount: 1
    serviceType: ClusterIP
    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: "4Gi"
      #storageClass: "standard"

  coordinator:
    name: coordinator
    replicaCount: 1
    serviceType: ClusterIP
    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: "30Gi"
      #storageClass: "standard"

  historical:
    name: historical
    replicaCount: 1
    serviceType: ClusterIP
    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: "4Gi"
      #storageClass: "standard"

  middleManager:
    name: middle-manager
    replicaCount: 1
    serviceType: ClusterIP
    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: "10Gi"
      #storageClass: "standard"

  router:
    name: router
    replicaCount: 1
    serviceType: NodePort
    nodePort: 30888
    persistence:
      enabled: true
      accessMode: ReadWriteOnce
      size: "4Gi"
      #storageClass: "standard"


eventview:
  enabled: true
  image:
    repository: prohankumar/eventview
    tag: 0.02
  redis:
    port: 6379
    password: redis_pass
  kafka:
    metadataMaxAgeMs: 300000
    consumerGroupID: eventview
  druid:
    taskDuration: PT10M
    completionTimeout: PT20M
  service:
    enabled: true
    httpPort: 80
    nodePort: 32074
    type: NodePort

kafkaadmin:
  enabled: true
  image:
    repository: prohankumar/kafkaadmin
    tag: 0.02
  kafka:
    kafkaConsumerGroupIDAdmin: kafkaAdmin
  druid:
    consumerInfoDataSource: consumerOffsetsTest3
    consumerInfoGranularity: hour
  service:
    enabled: true
    httpPort: 80
    nodePort: 32073
    type: NodePort

metadata:
  enabled: true
  image:
    repository: prohankumar/metadata
    tag: latest
  schemaSubjectNamePrefix: metadata
  service:
    enabled: true
    httpPort: 80
    nodePort: 32072
    type: NodePort

timebucket:
  enabled: true
  image:
    repository: prohankumar/timebucket
    tag: 0.02
  redis:
    port: 6379
    password: redis_pass
  kafka:
    metadataMaxAgeMs: 300000
    consumerGroupID: timeBucket
  service:
    enabled: true
    httpPort: 80
    nodePort: 32071
    type: NodePort


redis:
  image:
    registry: docker.io
    repository: bitnami/redis
    tag: 5.0.7-debian-9-r12
  cluster:
    enabled: true
    slaveCount: 2
  sentinel:
    enabled: false
  usePassword: true
  password: "redis_pass"
  master:
    disableCommands:
    - FLUSHDB
    - FLUSHALL
    service:
      type: NodePort
      port: 6379
      nodePort: 30679
    persistence:
      enabled: true
      size: 8Gi
  slave:
    service:
      type: ClusterIP
      port: 6379
    port: 6379
    disableCommands:
    - FLUSHDB
    - FLUSHALL
    persistence:
      enabled: true
      size: 8Gi


postgresql:
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: 11.6.0-debian-9-r0
  replication:
    enabled: false
    user: repl_user
    password: repl_password
    slaveReplicas: 1
  postgresqlPostgresPassword:
  postgresqlUsername: druid
  postgresqlPassword: FoolishPassword
  postgresqlDatabase: druid
  service:
    type: NodePort
    port: 5432
    nodePort: 32432
  persistence:
    enabled: true
    size: 8Gi